## 1.1 - F
Kapitel: 1.1 Verteilte Systeme in Hamburg 
Anzahl der Karteikarten: 10

## 1.1 - A
Karteikarte 1:
Frage: Was ist ein wichtiger Wirtschaftsstandort in Deutschland?
Antwort: Hamburg.

Karteikarte 2:
Frage: Welche Unternehmen sind auf innovative Technologien und Dienstleistungen angewiesen?
Antwort: Zahlreiche Unternehmen.

Karteikarte 3:
Frage: Was haben sich als zentrales Konzept in der Informatik etabliert?
Antwort: Verteilte Systeme.

Karteikarte 4:
Frage: Wofür werden verteilte Systeme genutzt?
Antwort: Zur Realisierung von Innovationen mit komplexen Anwendungen und Diensten.

Karteikarte 5:
Frage: Wo sind verteilte Anwendungen und Dienste oft verteilt?
Antwort: Über mehrere Standorte oder Rechenzentren.

Karteikarte 6:
Frage: Was ist das Ziel von verteilten Systemen?
Antwort: Die Realisierung von Innovationen mit komplexen Anwendungen und Diensten.

Karteikarte 7:
Frage: Welches Konzept hat sich als zentral in der Informatik etabliert?
Antwort: Verteilte Systeme.

Karteikarte 8:
Frage: Was ist eine angemessene Abgrenzung des Begriffs "Verteilte Systeme"?
Antwort: Folgt im nächsten Abschnitt des Kapitels.

Karteikarte 9:
Frage: Warum sind verteilte Systeme wichtig für Unternehmen in Hamburg?
Antwort: Weil sie auf innovative Technologien und Dienstleistungen angewiesen sind.

Karteikarte 10:
Frage: Was ist das Thema des Kapitels 1.1?
Antwort: Verteilte Systeme in Hamburg.

## 1.2 - F
Kapitel: 1.2 Definition Verteiltes System
Anzahl der Karteikarten: 10

## 1.2 - A
Karteikarte 1:
Frage: Was ist ein verteiltes System?
Antwort: Ein System, das aus mehreren autonomen Komponenten besteht, die über ein Netzwerk miteinander kommunizieren.

Karteikarte 2:
Frage: Was ist das Ziel von verteilten Systemen?
Antwort: Die Realisierung von Anwendungen und Diensten, die über mehrere Standorte oder Rechenzentren verteilt sind.

Karteikarte 3:
Frage: Was ist eine autonome Komponente in einem verteilten System?
Antwort: Eine Komponente, die unabhängig von anderen Komponenten agieren kann.

Karteikarte 4:
Frage: Was bedeutet es, dass Komponenten in einem verteilten System autonom sind?
Antwort: Sie können unabhängig voneinander agieren und Entscheidungen treffen.

Karteikarte 5:
Frage: Was ist der Zweck der Verteilung von Anwendungen und Diensten in einem verteilten System?
Antwort: Eine bessere Skalierbarkeit und Verfügbarkeit zu erreichen.

Karteikarte 6:
Frage: Welche Rolle spielt das Netzwerk bei einem verteilten System?
Antwort: Das Netzwerk ermöglicht die Kommunikation zwischen den autonomen Komponenten des Systems.

Karteikarte 7:
Frage: Was sind Beispiele für Anwendungen, die als verteilte Systeme realisiert werden können?
Antwort: E-Commerce-Systeme, soziale Netzwerke oder Cloud-Computing-Plattformen.

Karteikarte 8:
Frage: Welche Herausforderungen gibt es bei der Entwicklung von verteilten Systemen?
Antwort: Skalierbarkeit, Zuverlässigkeit, Sicherheit und Konsistenz.

Karteikarte 9:
Frage: Was ist der Unterschied zwischen einem verteilten und einem monolithischen System?
Antwort: Ein verteiltes System besteht aus mehreren autonomen Komponenten, während ein monolithisches System aus einer einzigen Komponente besteht.

Karteikarte 10:
Frage: Was sind die Vorteile von verteilten Systemen gegenüber monolithischen Systemen?
Antwort: Bessere Skalierbarkeit

## 1.3 - F
Kapitel: 1.3.1 Verteiltes und monolithisches System
Anzahl der Karteikarten: 5

## 1.3 - A
Karteikarte 1:
Frage: Was ist ein monolithisches System?
Antwort: Eine Softwarearchitektur, bei der alle Komponenten einer Anwendung in einer einzigen, großen Codebase zusammengefasst sind.

Karteikarte 2:
Frage: Was ist der Unterschied zwischen einem verteilten und einem monolithischen System?
Antwort: Ein verteiltes System besteht aus mehreren autonomen Komponenten, während ein monolithisches System aus einer einzigen Komponente besteht.

Karteikarte 3:
Frage: Was sind die Vorteile von monolithischen Systemen?
Antwort: Einfachere Entwicklung und Wartung, da alle Komponenten in einer Codebase zusammengefasst sind.

Karteikarte 4:
Frage: Was sind die Nachteile von monolithischen Systemen?
Antwort: Skalierbarkeit und Verfügbarkeit können begrenzt sein, da alle Komponenten auf demselben Server laufen.

Karteikarte 5:
Frage: Warum wird in diesem Dokument primär auf verteilte Systeme eingegangen?
Antwort: Weil verteilte Systeme eine bessere Skalierbarkeit und Verfügbarkeit bieten können als monolithische Systeme.

## 1.3.2 - F
Kapitel: 1.3.2 Verwandte Großrechner/Mainframes
Anzahl der Karteikarten: 5

## 1.3.2 - A
Karteikarte 1:
Frage: Was ist ein Großrechner?
Antwort: Ein leistungsstarkes Computersystem, das typischerweise in einem Rechenzentrum betrieben wird und für die Verarbeitung von großen Datenmengen und rechenintensiven Aufgaben verwendet wird.

Karteikarte 2:
Frage: Wo werden Großrechner typischerweise eingesetzt?
Antwort: In großen Unternehmen, Regierungsbehörden oder Forschungseinrichtungen.

Karteikarte 3:
Frage: Was zeichnet einen Großrechner aus?
Antwort: Hohe Leistung, Zuverlässigkeit, Verfügbarkeit und Sicherheit.

Karteikarte 4:
Frage: Was sind Beispiele für Anwendungen, die auf einem Großrechner laufen können?
Antwort: Simulationen, wissenschaftliche Berechnungen oder Geschäftsanwendungen.

Karteikarte 5:
Frage: Wie unterscheiden sich Großrechner von verteilten Systemen?
Antwort: Großrechner sind zentralisierte Systeme, während verteilte Systeme aus mehreren autonomen Komponenten bestehen.

## 1.3.3 - F
Kapitel: 1.3.3 Abstraktionsebenen
Anzahl der Karteikarten: 5

## 1.3.3 - A
Karteikarte 1:
Frage: Was sind Abstraktionsebenen in verteilten Systemen?
Antwort: Unterschiedliche Ebenen, auf denen ein verteiltes System abstrahiert und analysiert werden kann.

Karteikarte 2:
Frage: Warum fällt eine klare Definition von verteilten Systemen schwer?
Antwort: Weil verteilte Systeme nicht immer eine vergleichbare abstrahierte Struktur aufweisen.

Karteikarte 3:
Frage: Wie viele Abstraktionsebenen werden in diesem Kapitel betrachtet?
Antwort: Zwei Ebenen werden betrachtet, es gibt jedoch viele andere mögliche Einteilungen.

Karteikarte 4:
Frage: Was ist das Ziel der Analyse von verteilten Systemen auf verschiedenen Abstraktionsebenen?
Antwort: Eine bessere Verständlichkeit und Beherrschbarkeit des Systems zu erreichen.

Karteikarte 5:
Frage: Was sind Beispiele für Abstraktionsansätze in verteilten Systemen?
Antwort: Netzwerkprotokolle, Middleware oder Anwendungslogik.

## 1.3.4 - F
Kapitel: 1.3.4 Verteilte Systeme in AI und ITS
Anzahl der Karteikarten: 5

## 1.3.4 - A
Karteikarte 1:
Frage: Was ist der Unterschied zwischen Verteilten Systemen in der angewandten Informatik und in der technischen Informatik?
Antwort: Die Unterscheidung ist nicht immer klar abzugrenzen, da beide Bereiche sich oft überschneiden. Es gibt jedoch einige Unterschiede.

Karteikarte 2:
Frage: Warum wird in diesem Dokument der Begriff für die Angewandte Informatik und der Informatik für Technische Systeme diskutiert?
Antwort: Weil dieses Dokument primär in der Lehre eingesetzt werden soll.

Karteikarte 3:
Frage: Was sind Beispiele für Anwendungen von Verteilten Systemen in der angewandten Informatik?
Antwort: E-Commerce-Systeme, soziale Netzwerke oder Cloud-Computing-Plattformen.

Karteikarte 4:
Frage: Was sind Beispiele für Anwendungen von Verteilten Systemen in der technischen Informatik?
Antwort: Steuerungs- und Regelungssysteme, Automatisierungssysteme oder Prozessleitsysteme.

Karteikarte 5:
Frage: Warum überschneiden sich die Bereiche Verteilte Systeme in AI und ITS oft?
Antwort: Weil viele Anwendungen sowohl technische als auch anwendungsbezogene Aspekte haben.

## 1.3.5 - F 1
Kapitel: 1.3.5 Aspekte und Sichten
Anzahl der Karteikarten: 5

## 1.3.5 - A 1
Karteikarte 1:
Frage: Was sind Aspekte, unter denen ein verteiltes System diskutiert werden kann?
Antwort: Neben den Aspekten des Designs und der Architektur von Verteilten Systemen sowie der technologischen Basis können auch Skalierbarkeit und Ausfallsicherheit genannt werden.

Karteikarte 2:
Frage: Was ist Skalierbarkeit in Bezug auf verteilte Systeme?
Antwort: Die Fähigkeit eines Systems, mit steigender Last umzugehen.

Karteikarte 3:
Frage: Was ist Ausfallsicherheit in Bezug auf verteilte Systeme?
Antwort: Die Fähigkeit eines Systems, bei Ausfällen oder Fehlern in Teilen des Systems weiterhin zu funktionieren.

Karteikarte 4:
Frage: Warum müssen spezifische Skalierungs- und Wiederherstellungsmechanismen implementiert werden?
Antwort: Um sicherzustellen, dass ein verteiltes System auch bei hoher Last oder Ausfällen zuverlässig funktioniert.

Karteikarte 5:
Frage: Warum ist es wichtig, verschiedene Aspekte und Sichten von verteilten Systemen zu betrachten?
Antwort: Um ein umfassendes Verständnis des Systems zu erlangen und eine bessere Beherrschbarkeit und Verständlichkeit zu erreichen.

## 1.3.5 - F 2
Kapitel: 1.3.5 Aspekte und Sichten
Anzahl der Karteikarten: 10

## 1.3.5 - A 2
Karteikarte 1:
Frage: Was ist der implizierte Fokus der Diskussion in Bezug auf verteilte Systeme?
Antwort: Der implizierte Fokus lag bisher primär auf den Aspekten des Designs und der Architektur von Verteilten Systemen sowie der technologischen Basis.

Karteikarte 2:
Frage: Was sind weitere Aspekte, unter denen ein verteiltes System diskutiert werden kann?
Antwort: Skalierbarkeit und Ausfallsicherheit.

Karteikarte 3:
Frage: Was bedeutet Skalierbarkeit in Bezug auf verteilte Systeme?
Antwort: Die Fähigkeit eines Systems, mit steigender Last umzugehen.

Karteikarte 4:
Frage: Was bedeutet Ausfallsicherheit in Bezug auf verteilte Systeme?
Antwort: Die Fähigkeit eines Systems, bei Ausfällen oder Fehlern in Teilen des Systems weiterhin zu funktionieren.

Karteikarte 5:
Frage: Warum müssen spezifische Skalierungs- und Wiederherstellungsmechanismen implementiert werden?
Antwort: Um sicherzustellen, dass ein verteiltes System auch bei hoher Last oder Ausfällen zuverlässig funktioniert.

Karteikarte 6:
Frage: Welche anderen Aspekte können noch genannt werden, unter denen ein verteiltes System diskutiert werden kann?
Antwort: Zum Beispiel Sicherheit, Datenschutz oder Performance.

Karteikarte 7:
Frage: Warum ist es wichtig, verschiedene Aspekte von verteilten Systemen zu betrachten?
Antwort: Um ein umfassendes Verständnis des Systems zu erlangen und eine bessere Beherrschbarkeit und Verständlichkeit zu erreichen.

Karteikarte 8:
Frage: Was ist eine Sicht auf ein verteiltes System?
Antwort: Eine bestimmte Perspektive oder Betrachtungsweise auf das System, die sich auf bestimmte Aspekte konzentriert.

Karteikarte 9:
Frage: Was sind Beispiele für verschiedene Sichten auf ein verteiltes System?
Antwort: Zum Beispiel die Netzwerksicht, die Anwendungssicht oder die Sicherheitssicht.

Karteikarte 10:
Frage: Warum ist es wichtig, verschiedene Sichten auf ein verteiltes System zu betrachten?
Antwort: Um ein umfassendes Verständnis des Systems zu erlangen und eine bessere Beherrschbarkeit und Verständlichkeit zu erreichen. Außerdem können verschiedene Sichten dazu beitragen, bestimmte Aspekte des Systems besser zu verstehen und gezielt zu optimieren.

## 1.4.1 - F
Kapitel: 1.4.1 Ressourcen-Sharing
Anzahl der Karteikarten: 5

## 1.4.1 - A
Karteikarte 1:
Frage: Was ist Ressourcen-Sharing in Bezug auf verteilte Systeme?
Antwort: Die gemeinsame Nutzung von Ressourcen wie Speicher, Rechenleistung oder Netzwerkbandbreite durch verschiedene Komponenten eines verteilten Systems.

Karteikarte 2:
Frage: Warum ist Ressourcen-Sharing wichtig in verteilten Systemen?
Antwort: Weil es dazu beiträgt, die Effizienz und Auslastung des Systems zu verbessern und Ressourcen optimal zu nutzen.

Karteikarte 3:
Frage: Was sind Beispiele für Ressourcen, die in verteilten Systemen geteilt werden können?
Antwort: Speicherplatz, Prozessorzeit, Netzwerkbandbreite oder Datenbankzugriffe.

Karteikarte 4:
Frage: Was sind Vorteile von Ressourcen-Sharing in verteilten Systemen?
Antwort: Eine höhere Effizienz und Auslastung des Systems sowie eine bessere Nutzung der verfügbaren Ressourcen.

Karteikarte 5:
Frage: Wie kann Ressourcen-Sharing in verteilten Systemen umgesetzt werden?
Antwort: Durch Mechanismen wie Load Balancing, Caching oder Replikation von Daten.

## 1.4.2 - F
Kapitel: 1.4.2 Offenheit
Anzahl der Karteikarten: 5

## 1.4.2 - A
Karteikarte 1:
Frage: Was bedeutet Offenheit in Bezug auf verteilte Systeme?
Antwort: Offenheit bezieht sich darauf, dass ein System so konzipiert sein sollte, dass es leicht zugänglich und anpassbar für Benutzer und Entwickler ist.

Karteikarte 2:
Frage: Warum ist Offenheit wichtig in verteilten Systemen?
Antwort: Weil es dazu beiträgt, die Flexibilität und Anpassungsfähigkeit des Systems zu erhöhen und die Integration von verschiedenen Komponenten zu erleichtern.

Karteikarte 3:
Frage: Was sind wohl-definierte Schnittstellen in Bezug auf Offenheit von verteilten Systemen?
Antwort: Schnittstellen, die klar definiert sind und es Benutzern und Entwicklern ermöglichen, auf Ressourcen und Funktionen des Systems zuzugreifen.

Karteikarte 4:
Frage: Was sind Vorteile von Offenheit in verteilten Systemen?
Antwort: Eine höhere Flexibilität und Anpassungsfähigkeit des Systems sowie eine bessere Integration von verschiedenen Komponenten.

Karteikarte 5:
Frage: Was ist ein Beispiel für Offenheit in verteilten Systemen?
Antwort: Ein Beispiel wäre die Verwendung von offenen Standards wie HTTP oder XML, die es verschiedenen Komponenten ermöglichen, miteinander zu kommunizieren.

## 1.4.3 - F
Kapitel: 1.4.3 Skalierbarkeit
Anzahl der Karteikarten: 10

## 1.4.3 - A
Karteikarte 1:
Frage: Was ist Skalierbarkeit in Bezug auf verteilte Systeme?
Antwort: Skalierbarkeit bezieht sich darauf, dass ein verteiltes System in der Lage sein sollte, sich an eine wachsende Anzahl von Benutzern und Ressourcen anzupassen und dabei eine gute Leistung zu bieten.

Karteikarte 2:
Frage: Warum ist Skalierbarkeit wichtig in verteilten Systemen?
Antwort: Weil es dazu beiträgt, dass das System auch bei steigender Last oder wachsender Anzahl von Benutzern zuverlässig funktioniert.

Karteikarte 3:
Frage: Was sind Beispiele für Skalierungstechniken in verteilten Systemen?
Antwort: Lastverteilung, Replikation von Daten oder horizontale Skalierung durch Hinzufügen weiterer Server.

Karteikarte 4:
Frage: Was ist horizontale Skalierung in Bezug auf verteilte Systeme?
Antwort: Horizontale Skalierung bezieht sich darauf, dass ein verteiltes System durch Hinzufügen weiterer Server horizontal erweitert wird.

Karteikarte 5:
Frage: Was ist vertikale Skalierung in Bezug auf verteilte Systeme?
Antwort: Vertikale Skalierung bezieht sich darauf, dass ein verteiltes System durch Erhöhung der Ressourcen (z.B. Speicher oder Prozessorleistung) eines einzelnen Servers skaliert wird.

Karteikarte 6:
Frage: Was sind Vorteile von Skalierbarkeit in verteilten Systemen?
Antwort: Eine höhere Zuverlässigkeit und Verfügbarkeit des Systems sowie eine bessere Anpassungsfähigkeit an sich ändernde Anforderungen.

Karteikarte 7:
Frage: Was ist Lastverteilung in Bezug auf verteilte Systeme?
Antwort: Lastverteilung bezieht sich darauf, dass die Last auf verschiedene Server im System verteilt wird, um eine gleichmäßige Auslastung zu erreichen.

Karteikarte 8:
Frage: Was ist Replikation von Daten in Bezug auf verteilte Systeme?
Antwort: Replikation von Daten bezieht sich darauf, dass Daten auf mehrere Server im System repliziert werden, um eine höhere Verfügbarkeit und Zuverlässigkeit zu gewährleisten.

Karteikarte 9:
Frage: Was sind Herausforderungen bei der Skalierung von verteilten Systemen?
Antwort: Herausforderungen können sein: die Koordination von verteilten Ressourcen, die Verwaltung von Datenkonsistenz und -integrität sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 10:
Frage: Wie kann man die Skalierbarkeit von verteilten Systemen verbessern?
Antwort: Durch den Einsatz skalierbarer Architekturen, wie z.B. Microservices oder Service-Oriented Architecture (SOA), sowie durch den Einsatz von Cloud-Computing-Technologien und automatisierten Skalierungslösungen.

## 1.4.4 - F
Kapitel: 1.4.4 Verteilungstransparenz
Anzahl der Karteikarten: 10

## 1.4.4 - A
Karteikarte 1:
Frage: Was ist Verteilungstransparenz in Bezug auf verteilte Systeme?
Antwort: Verteilungstransparenz bezieht sich darauf, dass Benutzer und Anwendungen nicht bewusst sein sollten, dass sie auf ein verteiltes System zugreifen.

Karteikarte 2:
Frage: Warum ist Verteilungstransparenz wichtig in verteilten Systemen?
Antwort: Weil es dazu beiträgt, die Komplexität des Systems zu reduzieren und die Benutzerfreundlichkeit zu erhöhen.

Karteikarte 3:
Frage: Was sind Beispiele für Verteilungstransparenz in verteilten Systemen?
Antwort: Verbergen von Netzwerkdetails, automatische Lastverteilung oder Replikation von Daten.

Karteikarte 4:
Frage: Was ist Netzwerktransparenz in Bezug auf Verteilungstransparenz?
Antwort: Netzwerktransparenz bezieht sich darauf, dass das verteilte System für den Benutzer wie ein einzelnes System erscheint und er keine Kenntnis von der Netzwerktopologie oder -architektur haben muss.

Karteikarte 5:
Frage: Was ist Orts-Transparenz in Bezug auf Verteilungstransparenz?
Antwort: Orts-Transparenz bezieht sich darauf, dass der Benutzer keine Kenntnis von der physischen Speicherorten der Ressourcen im verteilten System haben sollte.

Karteikarte 6:
Frage: Was ist Migrationstransparenz in Bezug auf Verteilungstransparenz?
Antwort: Migrationstransparenz bezieht sich darauf, dass der Benutzer keine Kenntnis davon haben sollte, wenn eine Ressource von einem Knoten im System auf einen anderen verschoben wird.

Karteikarte 7:
Frage: Was ist Replikationstransparenz in Bezug auf Verteilungstransparenz?
Antwort: Replikationstransparenz bezieht sich darauf, dass der Benutzer keine Kenntnis davon haben sollte, wenn Daten auf mehrere Server im System repliziert werden.

Karteikarte 8:
Frage: Was ist Fragmentierungstransparenz in Bezug auf Verteilungstransparenz?
Antwort: Fragmentierungstransparenz bezieht sich darauf, dass der Benutzer keine Kenntnis davon haben sollte, wenn Daten in Fragmente aufgeteilt und auf verschiedene Server im System verteilt werden.

Karteikarte 9:
Frage: Was sind Herausforderungen bei der Implementierung von Verteilungstransparenz?
Antwort: Herausforderungen können sein: die Verwaltung von Datenkonsistenz und -integrität, die Koordination von verteilten Ressourcen sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 10:
Frage: Wie kann man die Verteilungstransparenz in verteilten Systemen verbessern?
Antwort: Durch den Einsatz von Middleware-Technologien wie Remote Procedure Calls (RPC) oder Message-Oriented Middleware (MOM), sowie durch den Einsatz von automatisierten Skalierungslösungen und Überwachungstools.






## 1.4.5 - F
Kapitel: 1.4.5 Kohärentes System
Anzahl der Karteikarten: 5

## 1.4.5 - A
Karteikarte 1:
Frage: Was ist ein kohärentes System in Bezug auf verteilte Systeme?
Antwort: Ein kohärentes System bezieht sich darauf, dass das verteilte System für den Benutzer wie ein zentrales, lokales System erscheint, obwohl die Daten und Funktionen in Wirklichkeit auf verschiedenen Knoten im verteilten System umgesetzt und gespeichert sind.

Karteikarte 2:
Frage: Warum ist ein kohärentes System wichtig in verteilten Systemen?
Antwort: Weil es dazu beiträgt, die Benutzerfreundlichkeit zu erhöhen und die Komplexität des Systems zu reduzieren.

Karteikarte 3:
Frage: Was sind Beispiele für Technologien oder Ansätze zur Erreichung eines kohärenten Systems?
Antwort: Caching von Daten, Replikation von Daten oder Load Balancing.

Karteikarte 4:
Frage: Was ist Caching in Bezug auf ein kohärentes System?
Antwort: Caching bezieht sich darauf, dass häufig verwendete Daten im lokalen Speicher des Benutzers oder Anwendungsservers zwischengespeichert werden, um eine schnellere Antwortzeit zu erreichen.

Karteikarte 5:
Frage: Was sind Herausforderungen bei der Implementierung eines kohärenten Systems?
Antwort: Herausforderungen können sein: die Verwaltung von Datenkonsistenz und -integrität, die Koordination von verteilten Ressourcen sowie die Sicherstellung einer guten Leistung bei steigender Last.

## 1.5 - F
Kapitel: 1.5 Ziele im Anforderungsprozess
Anzahl der Karteikarten: 5

## 1.5 - A
Karteikarte 1:
Frage: Was sind Ziele im Anforderungsprozess für verteilte Systeme?
Antwort: Die Ziele im Anforderungsprozess für verteilte Systeme beziehen sich darauf, die Anforderungen des Systems klar zu definieren, um sicherzustellen, dass das System die beabsichtigten Ziele erfüllt und die Anforderungen erfüllt.

Karteikarte 2:
Frage: Warum ist es wichtig, klare Ziele im Anforderungsprozess zu haben?
Antwort: Weil es dazu beiträgt, dass das System effektiv und effizient arbeitet und den Bedürfnissen der Benutzer entspricht.

Karteikarte 3:
Frage: Was sind Beispiele für Ziele im Anforderungsprozess für verteilte Systeme?
Antwort: Skalierbarkeit, Verfügbarkeit, Zuverlässigkeit oder Sicherheit.

Karteikarte 4:
Frage: Was ist Skalierbarkeit in Bezug auf Ziele im Anforderungsprozess?
Antwort: Skalierbarkeit bezieht sich darauf, dass das System in der Lage sein sollte, mit steigender Last umzugehen und sich an veränderte Bedingungen anzupassen.

Karteikarte 5:
Frage: Was sind Herausforderungen bei der Definition von Zielen im Anforderungsprozess für verteilte Systeme?
Antwort: Herausforderungen können sein: die Identifizierung der Bedürfnisse und Erwartungen der Benutzer, die Berücksichtigung von technischen Einschränkungen sowie die Abstimmung der verschiedenen Stakeholder.

## 1.6 - F
Kapitel: 1.6 Pitfalls der Verteilten Systeme
Anzahl der Karteikarten: 10

## 1.6 - A
Karteikarte 1:
Frage: Was sind die "Eight Fallacies of Distributed Computing"?
Antwort: Die "Eight Fallacies of Distributed Computing" sind acht falsche Annahmen, die oft in verteilten Systemen gemacht werden und von L. Peter Deutsch formuliert wurden. Eine dieser Annahmen ist, dass das Netzwerk immer verfügbar und zuverlässig ist.

Karteikarte 2:
Frage: Warum sind die "Eight Fallacies of Distributed Computing" wichtig?
Antwort: Weil sie dazu beitragen, immer wiederkehrende Fehler in verteilten Systemen zu vermeiden und das Verständnis für die Komplexität von verteilten Systemen zu verbessern.

Karteikarte 3:
Frage: Was ist die Annahme, dass das Netzwerk immer verfügbar ist?
Antwort: Die Annahme geht davon aus, dass das Netzwerk immer verfügbar und zuverlässig ist und dass das System immer in der Lage ist, auf das Netzwerk zuzugreifen.

Karteikarte 4:
Frage: Was sind weitere Beispiele für die "Eight Fallacies of Distributed Computing"?
Antwort: Weitere Beispiele sind unter anderem die Annahmen, dass Latenzzeit null ist, Bandbreite unendlich ist oder dass es nur ein Administrator im System gibt.

Karteikarte 5:
Frage: Warum können falsche Annahmen in verteilten Systemen problematisch sein?
Antwort: Weil sie dazu führen können, dass das System nicht wie erwartet funktioniert oder sogar Ausfälle verursacht.

Karteikarte 6:
Frage: Wie kann man falsche Annahmen in verteilten Systemen vermeiden?
Antwort: Indem man sich bewusst ist, dass sie existieren und indem man die Komplexität des Systems versteht.

Karteikarte 7:
Frage: Was sind Herausforderungen bei der Entwicklung von verteilten Systemen?
Antwort: Herausforderungen können sein: die Verwaltung von Datenkonsistenz und -integrität, die Koordination von verteilten Ressourcen sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 8:
Frage: Wie kann man Herausforderungen bei der Entwicklung von verteilten Systemen bewältigen?
Antwort: Durch den Einsatz von Middleware-Technologien wie Remote Procedure Calls (RPC) oder Message-Oriented Middleware (MOM), sowie durch den Einsatz von automatisierten Skalierungslösungen und Überwachungstools.

Karteikarte 9:
Frage: Was ist Fragmentierungstransparenz in Bezug auf verteilte Systeme?
Antwort: Fragmentierungstransparenz bezieht sich darauf, dass der Benutzer keine Kenntnis davon haben sollte, wenn Daten in Fragmente aufgeteilt und auf verschiedene Server im System verteilt werden.

Karteikarte 10:
Frage: Warum ist es wichtig, sich der Herausforderungen und Fallstricke bei der Entwicklung von verteilten Systemen bewusst zu sein?
Antwort: Weil es dazu beiträgt, dass das System effektiv und effizient arbeitet und den Bedürfnissen der Benutzer entspricht.

## 2.1.1 - F
Kapitel: 2.1.1 Funktionale vs. ressourcenorientierte Zerlegung
Anzahl der Karteikarten: 10

## 2.1.1 - A
Karteikarte 1:
Frage: Was ist funktionale Zerlegung in Bezug auf verteilte Systeme?
Antwort: Funktionale Zerlegung bezieht sich darauf, dass das System in verschiedene Funktionen oder Dienste aufgeteilt wird, die unabhängig voneinander arbeiten können.

Karteikarte 2:
Frage: Was ist ressourcenorientierte Zerlegung in Bezug auf verteilte Systeme?
Antwort: Ressourcenorientierte Zerlegung bezieht sich darauf, dass das System in verschiedene Ressourcen oder Datenobjekte aufgeteilt wird, die unabhängig voneinander verwaltet werden können.

Karteikarte 3:
Frage: Was sind Vor- und Nachteile der funktionalen Zerlegung?
Antwort: Vorteile sind unter anderem eine klare Trennung von Verantwortlichkeiten und eine einfache Skalierbarkeit. Nachteile können sein, dass es schwieriger sein kann, die Interaktion zwischen den verschiedenen Funktionen zu koordinieren.

Karteikarte 4:
Frage: Was sind Vor- und Nachteile der ressourcenorientierten Zerlegung?
Antwort: Vorteile sind unter anderem eine klare Trennung von Datenverantwortlichkeiten und eine einfachere Koordination von Datenzugriffen. Nachteile können sein, dass es schwieriger sein kann, die Interaktion zwischen den verschiedenen Ressourcen zu koordinieren.

Karteikarte 5:
Frage: Wie kann man entscheiden, welche Art der Zerlegung für ein verteiltes System am besten geeignet ist?
Antwort: Indem man die Anforderungen des Systems und die Art der Daten und Funktionen, die im System vorhanden sind, berücksichtigt.

Karteikarte 6:
Frage: Was ist Interface in Bezug auf funktionale Zerlegung?
Antwort: Interface bezieht sich darauf, wie verschiedene Funktionen oder Dienste miteinander kommunizieren und wie sie ihre Ergebnisse austauschen.

Karteikarte 7:
Frage: Was ist Relation in Bezug auf ressourcenorientierte Zerlegung?
Antwort: Relation bezieht sich darauf, wie verschiedene Ressourcen oder Datenobjekte miteinander verknüpft sind und wie sie miteinander interagieren.

Karteikarte 8:
Frage: Was sind Herausforderungen bei der funktionalen Zerlegung?
Antwort: Herausforderungen können sein: die Koordination von verschiedenen Funktionen, die Verwaltung von Datenkonsistenz und -integrität sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 9:
Frage: Was sind Herausforderungen bei der ressourcenorientierten Zerlegung?
Antwort: Herausforderungen können sein: die Verwaltung von Datenzugriffen und -verantwortlichkeiten, die Koordination von verschiedenen Ressourcen sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 10:
Frage: Wie kann man Herausforderungen bei der funktionalen und ressourcenorientierten Zerlegung bewältigen?
Antwort: Durch den Einsatz von Middleware-Technologien wie Remote Procedure Calls (RPC) oder Message-Oriented Middleware (MOM), sowie durch den Einsatz von automatisierten Skalierungslösungen und Überwachungstools.

## 2.1.2 - F
Kapitel: 2.1.2 Datenseparation
Anzahl der Karteikarten: 5

## 2.1.2 - A
Karteikarte 1:
Frage: Was ist Datenseparation in Bezug auf verteilte Systeme?
Antwort: Datenseparation bezieht sich darauf, dass Daten auf verschiedene Knoten im Netzwerk verteilt werden, um die Leistung, Skalierbarkeit und Zuverlässigkeit des Systems zu verbessern.

Karteikarte 2:
Frage: Wie wird Datenseparation in verteilten Systemen erreicht?
Antwort: Durch die Aufteilung von Daten in kleine Teile und deren Verteilung auf verschiedene Knoten oder Server im Netzwerk.

Karteikarte 3:
Frage: Was sind Vorteile der Datenseparation?
Antwort: Vorteile sind unter anderem eine bessere Leistung und Skalierbarkeit des Systems sowie eine höhere Zuverlässigkeit durch Redundanz.

Karteikarte 4:
Frage: Was sind Herausforderungen bei der Datenseparation?
Antwort: Herausforderungen können sein: die Verwaltung von Datenkonsistenz und -integrität, die Koordination von Datenzugriffen sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 5:
Frage: Wie kann man Herausforderungen bei der Datenseparation bewältigen?
Antwort: Durch den Einsatz von Middleware-Technologien wie Remote Procedure Calls (RPC) oder Message-Oriented Middleware (MOM), sowie durch den Einsatz von automatisierten Skalierungslösungen und Überwachungstools.

## 2.1.3 - F
Kapitel: 2.1.3 Schnittstellen zwischen den Entitäten
Anzahl der Karteikarten: 10

## 2.1.3 - A
Karteikarte 1:
Frage: Was sind Schnittstellen in Bezug auf verteilte Systeme?
Antwort: Schnittstellen beziehen sich darauf, wie verschiedene Entitäten in einem verteilten System miteinander kommunizieren und wie sie ihre Ergebnisse austauschen.

Karteikarte 2:
Frage: Warum benötigen verteilte Systeme Schnittstellen?
Antwort: Weil die verschiedenen Entitäten in einem verteilten System miteinander kommunizieren müssen, um Daten auszutauschen und ihre Arbeit zu koordinieren.

Karteikarte 3:
Frage: Was sind Herausforderungen bei der Entwicklung von Schnittstellen in verteilten Systemen?
Antwort: Herausforderungen können sein: die Verwaltung von Datenkonsistenz und -integrität, die Koordination von Datenzugriffen sowie die Sicherstellung einer guten Leistung bei steigender Last.

Karteikarte 4:
Frage: Was ist Remote Procedure Call (RPC) in Bezug auf Schnittstellen?
Antwort: RPC ist eine Middleware-Technologie, die es ermöglicht, dass verschiedene Entitäten in einem verteilten System miteinander kommunizieren können, indem sie Methodenaufrufe über das Netzwerk senden.

Karteikarte 5:
Frage: Was ist Message-Oriented Middleware (MOM) in Bezug auf Schnittstellen?
Antwort: MOM ist eine Middleware-Technologie, die es ermöglicht, dass verschiedene Entitäten in einem verteilten System miteinander kommunizieren können, indem sie Nachrichten über das Netzwerk senden.

Karteikarte 6:
Frage: Was sind Vor- und Nachteile von RPC als Middleware-Technologie?
Antwort: Vorteile sind unter anderem eine einfache Implementierung und eine hohe Leistung. Nachteile können sein, dass es schwieriger sein kann, die Interaktion zwischen den verschiedenen Entitäten zu koordinieren.

Karteikarte 7:
Frage: Was sind Vor- und Nachteile von MOM als Middleware-Technologie?
Antwort: Vorteile sind unter anderem eine bessere Skalierbarkeit und Zuverlässigkeit sowie eine einfachere Koordination von Nachrichten. Nachteile können sein, dass es schwieriger sein kann, die Interaktion zwischen den verschiedenen Entitäten zu koordinieren und dass die Implementierung komplexer sein kann.

Karteikarte 8:
Frage: Was ist ein API in Bezug auf Schnittstellen?
Antwort: Eine API (Application Programming Interface) ist eine Sammlung von Methoden und Funktionen, die es anderen Entwicklern ermöglicht, auf eine bestimmte Software oder Plattform zuzugreifen und mit ihr zu interagieren.

Karteikarte 9:
Frage: Was sind RESTful APIs in Bezug auf Schnittstellen?
Antwort: RESTful APIs sind eine Art von API, die auf dem REST (Representational State Transfer) Architekturstil basieren und es ermöglichen, dass verschiedene Entitäten in einem verteilten System miteinander kommunizieren können, indem sie HTTP-Methoden wie GET, POST, PUT und DELETE verwenden.

Karteikarte 10:
Frage: Was sind Vor- und Nachteile von RESTful APIs als Middleware-Technologie?
Antwort: Vorteile sind unter anderem eine einfache Implementierung und eine hohe Skalierbarkeit. Nachteile können sein, dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren.

## 2.1.4 - F
Kapitel: 2.1.4 Kopplung in verteilten Systemen
Anzahl der Karteikarten: 5

## 2.1.4 - A
Karteikarte 1:
Frage: Was ist Kopplung in Bezug auf verteilte Systeme?
Antwort: Kopplung bezieht sich darauf, wie stark verschiedene Entitäten in einem verteilten System voneinander abhängig sind.

Karteikarte 2:
Frage: Was ist lose Kopplung in Bezug auf verteilte Systeme?
Antwort: Lose Kopplung bedeutet, dass die verschiedenen Entitäten in einem verteilten System unabhängig voneinander arbeiten können und nur minimale Abhängigkeiten untereinander haben.

Karteikarte 3:
Frage: Was ist starke Kopplung in Bezug auf verteilte Systeme?
Antwort: Starke Kopplung bedeutet, dass die verschiedenen Entitäten in einem verteilten System stark voneinander abhängig sind und eng miteinander verbunden sind.

Karteikarte 4:
Frage: Was sind Vor- und Nachteile von lose gekoppelten Systemen?
Antwort: Vorteile sind unter anderem eine höhere Flexibilität und Skalierbarkeit sowie eine einfachere Wartbarkeit. Nachteile können sein, dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren.

Karteikarte 5:
Frage: Was sind Vor- und Nachteile von stark gekoppelten Systemen?
Antwort: Vorteile sind unter anderem eine einfachere Koordination von Interaktionen zwischen den verschiedenen Entitäten sowie eine höhere Effizienz. Nachteile können sein, dass es schwieriger sein kann, Änderungen an einem Teil des Systems vorzunehmen, ohne Auswirkungen auf andere Teile des Systems zu haben.

## 2.1.5 - F
Kapitel: 2.1.5 Mechanismen und Policies
Anzahl der Karteikarten: 5

## 2.1.5 - A
Karteikarte 1:
Frage: Was sind Mechanismen in Bezug auf verteilte Systeme?
Antwort: Mechanismen beziehen sich auf die technischen Mittel, die verwendet werden, um verschiedene Entitäten in einem verteilten System miteinander zu verbinden und zu koordinieren.

Karteikarte 2:
Frage: Was sind Policies in Bezug auf verteilte Systeme?
Antwort: Policies beziehen sich auf die Regeln und Vorschriften, die festlegen, wie verschiedene Entitäten in einem verteilten System miteinander interagieren sollen.

Karteikarte 3:
Frage: Was ist Load Balancing in Bezug auf Mechanismen und Policies?
Antwort: Load Balancing ist ein Mechanismus, der verwendet wird, um die Last zwischen verschiedenen Knoten oder Servern in einem verteilten System zu verteilen, um eine bessere Leistung und Skalierbarkeit zu erreichen.

Karteikarte 4:
Frage: Was ist Failover in Bezug auf Mechanismen und Policies?
Antwort: Failover ist ein Mechanismus, der verwendet wird, um sicherzustellen, dass ein verteiltes System auch dann weiterhin funktioniert, wenn ein Knoten oder Server ausfällt. Dabei übernimmt ein anderer Knoten oder Server automatisch die Aufgaben des ausgefallenen Knotens oder Servers.

Karteikarte 5:
Frage: Was sind Vor- und Nachteile von Load Balancing und Failover als Mechanismen und Policies?
Antwort: Vorteile sind unter anderem eine höhere Leistung, Skalierbarkeit und Zuverlässigkeit des Systems. Nachteile können sein, dass es schwieriger sein kann, die Interaktionen zwischen den verschiedenen Entitäten zu koordinieren und dass die Implementierung komplexer sein kann.

## 2.1.6 - F
Kapitel: 2.1.6 Stateful und stateless
Anzahl der Karteikarten: 5

## 2.1.6 - A
Karteikarte 1:
Frage: Was bedeutet "stateful" in Bezug auf verteilte Systeme?
Antwort: "Stateful" bezieht sich darauf, dass ein System Informationen über den aktuellen Zustand der Kommunikation zwischen den Komponenten speichert und auf vorherige Anfragen oder Interaktionen Bezug nimmt.

Karteikarte 2:
Frage: Was bedeutet "stateless" in Bezug auf verteilte Systeme?
Antwort: "Stateless" bezieht sich darauf, dass ein System keine Informationen über den aktuellen Zustand der Kommunikation zwischen den Komponenten speichert und jede Anfrage oder Interaktion unabhängig voneinander behandelt.

Karteikarte 3:
Frage: Was sind Vor- und Nachteile von stateful Systemen?
Antwort: Vorteile sind unter anderem individuellere oder optimierte Antworten aufgrund von früheren Interaktionen. Nachteile können sein, dass die Implementierung komplexer sein kann und dass es schwieriger sein kann, die Interaktionen zwischen den verschiedenen Entitäten zu koordinieren.

Karteikarte 4:
Frage: Was sind Vor- und Nachteile von stateless Systemen?
Antwort: Vorteile sind unter anderem eine einfachere Implementierung und eine höhere Skalierbarkeit. Nachteile können sein, dass es schwieriger sein kann, individuelle oder optimierte Antworten zu liefern und dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren.

Karteikarte 5:
Frage: Wie beeinflussen stateful und stateless Systeme die Architektur von verteilten Systemen?
Antwort: Die Wahl zwischen stateful und stateless Systemen beeinflusst die Art und Weise, wie die verschiedenen Entitäten in einem verteilten System miteinander kommunizieren und wie sie ihre Arbeit koordinieren. Je nach den Anforderungen des Systems kann es sinnvoll sein, entweder ein stateful oder ein stateless System zu verwenden oder eine Kombination aus beiden.

## 2.1.7 - F
Kapitel: 2.1.7 Transaktion
Anzahl der Karteikarten: 5

## 2.1.7 - A
Karteikarte 1:
Frage: Was ist eine Transaktion in Bezug auf verteilte Systeme?
Antwort: Eine Transaktion ist eine Sequenz von Operationen, die auf verteilten Ressourcen oder Daten ausgeführt werden, um eine bestimmte Aufgabe oder Funktion zu erfüllen.

Karteikarte 2:
Frage: Warum sind Transaktionen wichtig in verteilten Systemen?
Antwort: Transaktionen sind wichtig, um die Konsistenz und Integrität von Daten in verteilten Systemen zu gewährleisten, insbesondere bei gleichzeitigen Zugriffen und Änderungen durch verschiedene Benutzer oder Prozesse.

Karteikarte 3:
Frage: Was ist das ACID-Modell in Bezug auf Transaktionen?
Antwort: Das ACID-Modell (Atomicity, Consistency, Isolation, Durability) ist ein Modell für die Durchführung von Transaktionen in verteilten Systemen. Es stellt sicher, dass Transaktionen atomar (entweder vollständig ausgeführt oder gar nicht), konsistent (die Daten bleiben konsistent), isoliert (Transaktionen beeinflussen sich nicht gegenseitig) und dauerhaft (die Ergebnisse der Transaktion bleiben erhalten) sind.

Karteikarte 4:
Frage: Was sind Vor- und Nachteile von Transaktionen in verteilten Systemen?
Antwort: Vorteile sind unter anderem eine höhere Konsistenz und Integrität der Daten sowie eine bessere Skalierbarkeit des Systems. Nachteile können sein, dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren und dass die Implementierung komplexer sein kann.

Karteikarte 5:
Frage: Wie beeinflussen Transaktionen die Architektur von verteilten Systemen?
Antwort: Die Verwendung von Transaktionen beeinflusst die Art und Weise, wie die verschiedenen Entitäten in einem verteilten System miteinander kommunizieren und wie sie ihre Arbeit koordinieren. Je nach den Anforderungen des Systems kann es sinnvoll sein, Transaktionen zu verwenden oder alternative Mechanismen zu wählen.

## 2.1.8 - F
Kapitel: 2.1.8 Message Passing
Anzahl der Karteikarten: 5

## 2.1.8 - A (1)
Karteikarte 1:
Frage: Was ist Message Passing in Bezug auf verteilte Systeme?
Antwort: Message Passing ist ein Kommunikationsparadigma in verteilten Systemen, bei dem Prozesse oder Komponenten Nachrichten austauschen, um Daten zu übertragen oder Aufgaben zu koordinieren.

Karteikarte 2:
Frage: Was sind Beispiele für Anwendungen von Message Passing in verteilten Systemen?
Antwort: Beispiele für Anwendungen von Message Passing sind Remote Procedure Calls (RPC), Remote Method Invocation (RMI) und andere Mechanismen, die verwendet werden, um die Kommunikation zwischen verschiedenen Entitäten in einem verteilten System zu ermöglichen.

Karteikarte 3:
Frage: Was sind Vor- und Nachteile von Message Passing als Kommunikationsparadigma?
Antwort: Vorteile sind unter anderem eine höhere Flexibilität und Skalierbarkeit sowie eine einfachere Wartbarkeit. Nachteile können sein, dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren und dass die Implementierung komplexer sein kann.

Karteikarte 4:
Frage: Wie beeinflusst Message Passing die Architektur von verteilten Systemen?
Antwort: Die Verwendung von Message Passing beeinflusst die Art und Weise, wie die verschiedenen Entitäten in einem verteilten System miteinander kommunizieren und wie sie ihre Arbeit koordinieren. Je nach den Anforderungen des Systems kann es sinnvoll sein, Message Passing zu verwenden oder alternative Mechanismen zu wählen.

Karteikarte 5:
Frage: Was sind weitere Anwendungen von Message Passing außerhalb von verteilten Systemen?
Antwort: Message Passing ist auch ein Konzept für die Nebenläufigkeits-Programmierung (Concurrent programming), der parallelen Programmierung (Parallel programming), der objektorientierten Programmierung und der Interprozesskommunikation.

## 2.1.8 - A (2)
Karteikarte 1:
Frage: Was ist Message Passing in Bezug auf verteilte Systeme?
Antwort: Message Passing ist ein Kommunikationsparadigma in verteilten Systemen.

Karteikarte 2:
Frage: Was sind Beispiele für Anwendungen von Message Passing in verteilten Systemen?
Antwort: Beispiele sind Remote Procedure Calls (RPC), Remote Method Invocation (RMI) und andere Mechanismen.

Karteikarte 3:
Frage: Was sind Vor- und Nachteile von Message Passing als Kommunikationsparadigma?
Antwort: Vorteile sind Flexibilität, Skalierbarkeit und Wartbarkeit. Nachteile können Komplexität sein.

Karteikarte 4:
Frage: Wie beeinflusst Message Passing die Architektur von verteilten Systemen?
Antwort: Die Verwendung von Message Passing beeinflusst die Art und Weise, wie Entitäten kommunizieren und koordinieren.

Karteikarte 5:
Frage: Was sind weitere Anwendungen von Message Passing außerhalb von verteilten Systemen?
Antwort: Nebenläufigkeits-Programmierung, parallele Programmierung, objektorientierte Programmierung und Interprozesskommunikation.

## 2.1.9 - F
Kapitel: 2.1.9 Idempotent
Anzahl der Karteikarten: 5

## 2.1.9 - A
Karteikarte 1:
Frage: Was bedeutet "idempotent" in Bezug auf verteilte Systeme?
Antwort: "Idempotent" bezieht sich darauf, dass eine Operation mehrmals ausgeführt werden kann, ohne dass sich das Ergebnis ändert.

Karteikarte 2:
Frage: Warum sind idempotente Operationen nützlich in verteilten Systemen?
Antwort: Idempotente Operationen können dazu beitragen, die Fehler- und Ausfalltoleranz von verteilten Systemen zu erhöhen.

Karteikarte 3:
Frage: Was sind Beispiele für idempotente Operationen in verteilten Systemen?
Antwort: Beispiele für idempotente Operationen sind das Lesen von Daten oder das Löschen von Daten.

Karteikarte 4:
Frage: Was sind Vor- und Nachteile von idempotenten Operationen in verteilten Systemen?
Antwort: Vorteile sind unter anderem eine höhere Fehler- und Ausfalltoleranz sowie eine einfachere Implementierung. Nachteile können sein, dass nicht alle Operationen idempotent sein können und dass es schwieriger sein kann, komplexe Interaktionen zwischen den verschiedenen Entitäten zu koordinieren.

Karteikarte 5:
Frage: Wie beeinflussen idempotente Operationen die Architektur von verteilten Systemen?
Antwort: Die Verwendung von idempotenten Operationen beeinflusst die Art und Weise, wie Entitäten miteinander kommunizieren und wie sie ihre Arbeit koordinieren. Je nach den Anforderungen des Systems kann es sinnvoll sein, idempotente Operationen zu verwenden oder alternative Mechanismen zu wählen.

## 2.1.10 - F
Kapitel: 2.1.10 Distributed Hash Table, DHT
Anzahl der Karteikarten: 5

## 2.1.10 - A
Karteikarte 1:
Frage: Was ist eine Distributed Hash Table (DHT) in verteilten Systemen?
Antwort: Eine Distributed Hash Table (DHT) ist eine verteilte Datenstruktur, die es ermöglicht, Daten effizient auf einem Netzwerk von Computern zu speichern und abzurufen.

Karteikarte 2:
Frage: Wie funktioniert eine DHT?
Antwort: Eine DHT basiert auf einem konsistenten Hashing-Algorithmus und ordnet Knoten und Schlüssel im Netzwerk in einem logischen Ring an. Jeder Knoten und jeder Schlüssel wird durch eine eindeutige ID im Schlüsselraum repräsentiert. Um einen Wert für einen bestimmten Schlüssel zu speichern oder abzurufen, wird der Schlüssel durch dieselbe Hash-Funktion gehasht, die für die Erzeugung der Knoten-IDs verwendet wurde.

Karteikarte 3:
Frage: Was sind Vorteile von DHTs in verteilten Systemen?
Antwort: Vorteile von DHTs sind unter anderem eine höhere Skalierbarkeit, Verfügbarkeit und Ausfallsicherheit sowie eine effiziente Speicherung und Abfrage von Daten.

Karteikarte 4:
Frage: Was sind Anwendungen von DHTs in verteilten Systemen?
Antwort: Anwendungen von DHTs sind unter anderem Peer-to-Peer-Netzwerke, Content-Delivery-Netzwerke (CDNs) und Cloud-Speichersysteme.

Karteikarte 5:
Frage: Was sind Nachteile von DHTs in verteilten Systemen?
Antwort: Nachteile können sein, dass es schwieriger sein kann, komplexe Datenstrukturen zu implementieren und dass die Effizienz von DHTs von der Verteilung der Knoten im Netzwerk abhängt.

## 2.2.1 - F
Kapitel: 2.2.1 Schichtenarchitektur
Anzahl der Karteikarten: 10

## 2.2.1 - A
Karteikarte 1:
Frage: Was ist eine Schichtenarchitektur in verteilten Systemen?
Antwort: Eine Schichtenarchitektur ist eine hierarchische Struktur von Schichten, die bestimmte Funktionen und Dienste für ein verteiltes System bereitstellen.

Karteikarte 2:
Frage: Was sind Vorteile einer Schichtenarchitektur in verteilten Systemen?
Antwort: Vorteile sind unter anderem eine höhere Modularität, Flexibilität und Wartbarkeit sowie eine einfachere Implementierung von Sicherheitsmechanismen.

Karteikarte 3:
Frage: Wie funktioniert eine Schichtenarchitektur in verteilten Systemen?
Antwort: Eine Schichtenarchitektur besteht aus mehreren horizontalen Schichten, die jeweils bestimmte Funktionen und Dienste bereitstellen. Jede Schicht kommuniziert nur mit den direkt darüber oder darunter liegenden Schichten.

Karteikarte 4:
Frage: Was sind typische Schichten in einer Schichtenarchitektur von verteilten Systemen?
Antwort: Typische Schichten sind unter anderem die Präsentationsschicht, Anwendungsschicht, Geschäftslogikschicht und Datenspeicherschicht.

Karteikarte 5:
Frage: Was ist die Präsentationsschicht in einer Schichtenarchitektur von verteilten Systemen?
Antwort: Die Präsentationsschicht ist die oberste Schicht einer Schichtenarchitektur und stellt die Benutzeroberfläche für das verteilte System bereit.

Karteikarte 6:
Frage: Was ist die Anwendungsschicht in einer Schichtenarchitektur von verteilten Systemen?
Antwort: Die Anwendungsschicht ist die Schicht, die die Geschäftslogik des verteilten Systems implementiert und Schnittstellen für die Interaktion mit anderen Schichten bereitstellt.

Karteikarte 7:
Frage: Was ist die Geschäftslogikschicht in einer Schichtenarchitektur von verteilten Systemen?
Antwort: Die Geschäftslogikschicht ist die Schicht, die die Kernfunktionalität des verteilten Systems implementiert und Schnittstellen für die Interaktion mit anderen Schichten bereitstellt. Hier werden beispielsweise Datenvalidierung, Geschäftsregeln und Workflows implementiert.

Karteikarte 8:
Frage: Was ist die Datenspeicherschicht in einer Schichtenarchitektur von verteilten Systemen?
Antwort: Die Datenspeicherschicht ist die unterste Schicht einer Schichtenarchitektur und stellt Mechanismen für die Speicherung und Abfrage von Daten bereit.

Karteikarte 9:
Frage: Was sind Nachteile einer Schichtenarchitektur in verteilten Systemen?
Antwort: Nachteile können sein, dass eine zu starke Schichtung zu einem höheren Overhead führen kann und dass die Kommunikation zwischen den Schichten zusätzliche Latenzzeiten verursachen kann.

Karteikarte 10:
Frage: Was sind Alternativen zur Schichtenarchitektur in verteilten Systemen?
Antwort: Alternativen können sein, eine serviceorientierte Architektur (SOA) oder eine ereignisgesteuerte Architektur (EDA) zu verwenden.

## 2.2.2 - F
Kapitel: 2.2.2 Single Node
Anzahl der Karteikarten: 5

## 2.2.2 - A
Karteikarte 1:
Frage: Was ist eine Single-Node-Application?
Antwort: Eine Single-Node-Application ist ein Architekturtyp, bei dem die Anwendung auf einem einzelnen Knoten in einem verteilten System ausgeführt wird.

Karteikarte 2:
Frage: Was ist das Ziel einer Single-Node-Application?
Antwort: Das Ziel einer Single-Node-Application ist es, die Anwendung auf einem einzelnen Knoten auszuführen, ohne dass eine Verteilung der Funktionen oder Daten über den logischen/physikalischen Knoten hinaus erforderlich ist.

Karteikarte 3:
Frage: Was sind typische Knoten in einer Single-Node-Architektur?
Antwort: Typische Knoten können physische Server oder virtuelle Maschinen sein.

Karteikarte 4:
Frage: Was sind Vorteile einer Single-Node-Architektur?
Antwort: Vorteile sind unter anderem eine einfachere Implementierung und Wartung sowie eine höhere Performance durch die Vermeidung von Netzwerklatenzzeiten.

Karteikarte 5:
Frage: Was sind Nachteile einer Single-Node-Architektur?
Antwort: Nachteile können sein, dass Skalierbarkeit und Ausfallsicherheit begrenzt sind und dass es schwieriger sein kann, Sicherheitsmechanismen zu implementieren.

## 2.2.3 - F
Kapitel: 2.2.3 Middleware Architektur
Anzahl der Karteikarten: 10

## 2.2.3 - A
Karteikarte 1:
Frage: Was ist eine Middleware Architektur?
Antwort: Eine Middleware Architektur ist eine Schicht in einem verteilten System, die die Aufgaben der Verteilung in sich vereint und ein breites Angebot für die Kommunikation bereitstellt.

Karteikarte 2:
Frage: Was sind typische Aufgaben einer Middleware Architektur?
Antwort: Typische Aufgaben sind unter anderem die Bereitstellung von Schnittstellen für die Kommunikation zwischen verschiedenen Knoten im verteilten System, das Management von Transaktionen und das Routing von Nachrichten.

Karteikarte 3:
Frage: Was ist das Ziel einer Middleware Architektur?
Antwort: Das Ziel einer Middleware Architektur ist es, die Komplexität der Verteilung im verteilten System zu reduzieren und eine einheitliche Schnittstelle für die Kommunikation bereitzustellen.

Karteikarte 4:
Frage: Was sind Vorteile einer Middleware Architektur?
Antwort: Vorteile sind unter anderem eine höhere Flexibilität und Skalierbarkeit des verteilten Systems sowie eine einfachere Implementierung von Sicherheitsmechanismen.

Karteikarte 5:
Frage: Was sind Nachteile einer Middleware Architektur?
Antwort: Nachteile können sein, dass eine zu komplexe Middleware-Architektur zu einem höheren Overhead führen kann und dass es schwieriger sein kann, spezielle Anforderungen des verteilten Systems zu erfüllen.

Karteikarte 6:
Frage: Welche Funktion hat die Middleware in einem verteilten System?
Antwort: Die Funktion der Middleware besteht darin, als Vermittler zwischen den verschiedenen Knoten im verteilten System zu agieren und eine einheitliche Schnittstelle für die Kommunikation bereitzustellen.

Karteikarte 7:
Frage: Was ist das Ziel der Kapselung in einer Middleware Architektur?
Antwort: Das Ziel der Kapselung besteht darin, die Komplexität der Verteilung im verteilten System zu reduzieren und eine klare Trennung zwischen den verschiedenen Schichten des Systems zu schaffen.

Karteikarte 8:
Frage: Was sind typische Technologien, die in einer Middleware Architektur eingesetzt werden?
Antwort: Typische Technologien sind unter anderem Message-Oriented Middleware (MOM), Remote Procedure Call (RPC) und Web Services.

Karteikarte 9:
Frage: Was ist Message-Oriented Middleware (MOM)?
Antwort: Message-Oriented Middleware (MOM) ist eine Technologie, die auf dem Austausch von Nachrichten zwischen verschiedenen Knoten im verteilten System basiert.

Karteikarte 10:
Frage: Was sind typische Anwendungsfälle für eine Middleware Architektur?
Antwort: Typische Anwendungsfälle sind unter anderem E-Commerce-Systeme, Online-Banking-Systeme und Logistiksysteme.

## 2.2.4 - F
Kapitel: 2.2.4 Client-Server-Architektur
Anzahl der Karteikarten: 5

## 2.2.4 - A
Karteikarte 1:
Frage: Was ist eine Client-Server-Architektur?
Antwort: Eine Client-Server-Architektur ist eine Architektur, bei der die Aufgaben zwischen einem Client und einem Server aufgeteilt sind.

Karteikarte 2:
Frage: Was sind typische Aufgaben des Clients in einer Client-Server-Architektur?
Antwort: Typische Aufgaben des Clients sind unter anderem die Bereitstellung von Benutzeroberflächen und die Verarbeitung von Benutzereingaben.

Karteikarte 3:
Frage: Was sind typische Aufgaben des Servers in einer Client-Server-Architektur?
Antwort: Typische Aufgaben des Servers sind unter anderem die Verarbeitung von Anfragen des Clients und die Bereitstellung von Daten und Diensten.

Karteikarte 4:
Frage: Was ist das Ziel der Zustandslosigkeit in einer Client-Server-Architektur?
Antwort: Das Ziel der Zustandslosigkeit besteht darin, dass der Server keine Informationen über den aktuellen Zustand eines Clients zwischen den Anfragen speichert. Dadurch wird eine bessere Skalierbarkeit und Wartbarkeit der Server erreicht.

Karteikarte 5:
Frage: Welche Protokolle können in einer Client-Server-Architektur verwendet werden?
Antwort: Verschiedene Protokolle wie HTTP, FTP oder SMTP können in einer Client-Server-Architektur verwendet werden.

## 2.2.5 - F
Kapitel: 2.2.5 Event-Driven Architektur
Anzahl der Karteikarten: 5

## 2.2.5 - A
Karteikarte 1:
Frage: Was ist eine Event-Driven Architektur?
Antwort: Eine Event-Driven Architektur (EDA) ist ein Architekturansatz, bei dem die Kommunikation zwischen den Komponenten eines Systems durch Events oder Nachrichten stattfindet.

Karteikarte 2:
Frage: Wie funktioniert eine Event-Driven Architektur?
Antwort: In einer EDA reagieren die Komponenten auf Ereignisse, die von anderen Komponenten im System generiert werden, anstatt direkt miteinander zu kommunizieren.

Karteikarte 3:
Frage: Was sind Vorteile einer Event-Driven Architektur?
Antwort: Vorteile sind unter anderem eine höhere Entkopplung und Skalierbarkeit von Anwendungen sowie eine bessere Unterstützung von Echtzeitsystemen und komplexen, verteilt arbeitenden Umgebungen.

Karteikarte 4:
Frage: Was sind typische Anwendungsfälle für eine Event-Driven Architektur?
Antwort: Typische Anwendungsfälle sind unter anderem IoT-Anwendungen, Big Data-Anwendungen und Finanztransaktionssysteme.

Karteikarte 5:
Frage: Was ist der Unterschied zwischen einer Client-Server-Architektur und einer Event-Driven Architektur?
Antwort: Der Unterschied besteht darin, dass in einer Client-Server-Architektur die Kommunikation zwischen Client und Server über Anfragen und Antworten erfolgt, während in einer EDA die Kommunikation zwischen den Komponenten durch Events oder Nachrichten stattfindet.

## 2.2.6 - F
Kapitel: 2.2.6 Microservices-Architektur
Anzahl der Karteikarten: 5

## 2.2.6 - A
Karteikarte 1:
Frage: Was ist eine Microservices-Architektur?
Antwort: Eine Microservices-Architektur ist ein Architekturansatz, bei dem eine Anwendung aus mehreren kleinen, unabhängigen Diensten besteht, die über standardisierte APIs oder Messaging-Systeme kommunizieren.

Karteikarte 2:
Frage: Was sind Vorteile einer Microservices-Architektur?
Antwort: Vorteile sind unter anderem eine höhere Flexibilität, Wartbarkeit und Skalierbarkeit von Anwendungen sowie eine bessere Unterstützung von agilen Entwicklungsmethoden.

Karteikarte 3:
Frage: Was sind typische Aufgaben eines Dienstes in einer Microservices-Architektur?
Antwort: Typische Aufgaben eines Dienstes sind unter anderem die Verarbeitung von Benutzeranfragen, die Bereitstellung von Daten und die Integration mit anderen Diensten.

Karteikarte 4:
Frage: Was sind typische Anwendungsfälle für eine Microservices-Architektur?
Antwort: Typische Anwendungsfälle sind unter anderem E-Commerce-Systeme, Online-Banking-Systeme und Logistiksysteme.

Karteikarte 5:
Frage: Was ist der Unterschied zwischen einer Monolithischen Architektur und einer Microservices-Architektur?
Antwort: Der Unterschied besteht darin, dass in einer monolithischen Architektur alle Funktionen der Anwendung in einem einzigen Codeblock zusammengefasst sind, während in einer Microservices-Architektur die Funktionen auf mehrere unabhängige Dienste aufgeteilt sind.

## 2.2.7 - F
Kapitel: 2.2.7 Peer-to-Peer-Architektur
Anzahl der Karteikarten: 5

## 2.2.7 - A
Karteikarte 1:
Frage: Was ist eine Peer-to-Peer-Architektur?
Antwort: Eine Peer-to-Peer-Architektur (P2P) ist ein Architekturansatz, bei dem die Aufgaben zwischen den Knoten im Netzwerk aufgeteilt sind und jeder Knoten sowohl als Client als auch als Server fungieren kann.

Karteikarte 2:
Frage: Wie funktioniert eine Peer-to-Peer-Architektur?
Antwort: In einer P2P-Architektur kommunizieren die Knoten direkt miteinander, ohne dass ein zentraler Server erforderlich ist. Jeder Knoten kann Anfragen von anderen Knoten beantworten und selbst Anfragen an andere Knoten senden.

Karteikarte 3:
Frage: Was sind Vorteile einer Peer-to-Peer-Architektur?
Antwort: Vorteile sind unter anderem eine höhere Skalierbarkeit, Verfügbarkeit und Robustheit von Anwendungen sowie eine bessere Unterstützung von dezentralisierten Systemen.

Karteikarte 4:
Frage: Was sind typische Anwendungsfälle für eine Peer-to-Peer-Architektur?
Antwort: Typische Anwendungsfälle sind unter anderem Filesharing-Systeme, Instant-Messaging-Systeme und verteilte Datenbanken.

Karteikarte 5:
Frage: Was ist der Unterschied zwischen einer Client-Server-Architektur und einer Peer-to-Peer-Architektur?
Antwort: Der Unterschied besteht darin, dass in einer Client-Server-Architektur die Aufgaben zwischen einem zentralen Server und den Clients aufgeteilt sind, während in einer P2P-Architektur die Aufgaben zwischen den Knoten im Netzwerk aufgeteilt sind und jeder Knoten sowohl als Client als auch als Server fungieren kann.

## 2.2.8 - F
Kapitel: 2.2.8 Hexagonal Onion Architektur
Anzahl der Karteikarten: 5

## 2.2.8 - A
Karteikarte 1:
Frage: Was ist eine Hexagonal Onion Architektur?
Antwort: Eine Hexagonal Onion Architektur ist eine Kombination aus der hexagonalen Architektur und der Zwiebelarchitektur, die die Trennung von Anliegen fördert und die Testbarkeit, Wartbarkeit und Erweiterbarkeit von Softwareanwendungen verbessert.

Karteikarte 2:
Frage: Was ist das Ziel der hexagonalen Architektur in einer Hexagonal Onion Architektur?
Antwort: Das Ziel der hexagonalen Architektur besteht darin, dass die Kernlogik des Systems unabhängig von externen Einflüssen wie Benutzerschnittstellen, Datenbanken und Frameworks bleibt.

Karteikarte 3:
Frage: Was ist das Ziel der Zwiebelarchitektur in einer Hexagonal Onion Architektur?
Antwort: Das Ziel der Zwiebelarchitektur besteht darin, dass die Anwendung in Schichten organisiert wird, wobei jede Schicht nur auf die darunterliegenden Schichten zugreifen kann.

Karteikarte 4:
Frage: Was sind Ports und Adapter in einer Hexagonal Onion Architektur?
Antwort: Ports und Adapter dienen als Schnittstelle zwischen der Kernlogik des Systems und externen Anliegen wie Benutzerschnittstellen, Datenbanken und Frameworks.

Karteikarte 5:
Frage: Was sind Vorteile einer Hexagonal Onion Architektur?
Antwort: Vorteile sind unter anderem eine höhere Testbarkeit, Wartbarkeit und Erweiterbarkeit von Softwareanwendungen sowie eine bessere Trennung von Anliegen und eine höhere Unabhängigkeit von externen Einflüssen.

## 2.2.9 - F
Kapitel: 2.2.9 Time triggered vs event triggert
Anzahl der Karteikarten: 5

## 2.2.9 - A
Karteikarte 1:
Frage: Was ist der Unterschied zwischen einer zeitgesteuerten und einer ereignisgesteuerten Architektur?
Antwort: Der Unterschied besteht darin, dass in zeitgesteuerten Systemen alle Knoten synchronisiert sind und einem festen Zeitplan folgen, während in ereignisgesteuerten Systemen die Knoten nicht streng synchronisiert sind und die Kommunikation zwischen den Knoten durch das Auftreten von Ereignissen ausgelöst wird.

Karteikarte 2:
Frage: Wie funktioniert eine zeitgesteuerte Architektur?
Antwort: In einer zeitgesteuerten Architektur sind alle Knoten synchronisiert und folgen einem festen Zeitplan. Die Kommunikation zwischen den Knoten findet zu vorher festgelegten Zeitpunkten statt.

Karteikarte 3:
Frage: Wie funktioniert eine ereignisgesteuerte Architektur?
Antwort: In einer ereignisgesteuerten Architektur sind die Knoten nicht streng synchronisiert. Die Kommunikation zwischen den Knoten wird durch das Auftreten von Ereignissen ausgelöst, die nicht an einen festen Zeitplan gebunden sind.

Karteikarte 4:
Frage: Was sind Vorteile einer zeitgesteuerten Architektur?
Antwort: Vorteile sind unter anderem eine höhere Vorhersagbarkeit und Stabilität des Systems sowie eine bessere Unterstützung von Echtzeitsystemen.

Karteikarte 5:
Frage: Was sind Vorteile einer ereignisgesteuerten Architektur?
Antwort: Vorteile sind unter anderem eine höhere Flexibilität und Anpassungsfähigkeit des Systems sowie eine bessere Unterstützung von komplexen, verteilt arbeitenden Umgebungen.